{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run GameEnv.ipynb\n",
    "\n",
    "from torch.nn import Module, Conv1d, Conv2d, Linear, ReLU, LayerNorm, Sequential, MultiheadAttention\n",
    "from torch.nn.functional import pad\n",
    "from torch import cat\n",
    "from torch import tensor\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAPnet(Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        \n",
    "        n_species = env.n_species\n",
    "        n_foods = env.n_foods\n",
    "        n_status = env.n_status  # 17\n",
    "        n_team_pet_data = 7      # atk, hp, lvl, exp, pos, temp_atk, temp_hp\n",
    "        n_shop_pet_data = 4      # atk, hp, cost, is_frozen\n",
    "        n_foods_data = 2          # cost, is_frozen\n",
    "        self.n_data = env.n_data       # gold, lives, wins, turn, lost_last_battle, n_actions_left\n",
    "        n_actions = env.n_actions\n",
    "        \n",
    "        # Team(5x90) -> Conv2d(20) -> RELU -> Conv1d(50) -> RELU -> (5x50)\n",
    "        team_pet_length = n_team_pet_data + n_species + n_status\n",
    "        team_nchannels1 = 20\n",
    "        team_nchannels2 = 50\n",
    "        team_kernel_size = (3,)\n",
    "        \n",
    "        self.conv2d = Conv2d(1, team_nchannels1, (3, team_pet_length), padding =(1,0))\n",
    "        self.relu1 = ReLU()\n",
    "        self.conv1d = Conv1d(team_nchannels1, team_nchannels2, (3,), padding=1)\n",
    "        self.team_norm = LayerNorm(Team.max_size)\n",
    "        \n",
    "        # Shop(7x90) -> MultiSelfAttention(92,4) -> Resid+Norm -> Linear(92) -> ReLU -> Linear(32) -> Norm -> (7x32)\n",
    "        shop_nheads = 4\n",
    "        shop_input_size = n_shop_pet_data + n_species\n",
    "        shop_npad = shop_nheads - (shop_input_size % shop_nheads)\n",
    "        shop_input_size += shop_npad\n",
    "        shop_output_size = 32\n",
    "        \n",
    "        self.shop_pad = (0, shop_npad)\n",
    "        self.attention1 = MultiheadAttention(shop_input_size, shop_nheads)\n",
    "        self.attention2 = MultiheadAttention(shop_input_size, shop_nheads)\n",
    "        self.shop_norm1 = LayerNorm(shop_input_size)\n",
    "        self.shop_norm2 = LayerNorm(shop_input_size)\n",
    "        self.ff1 = Sequential(Linear(shop_input_size, 2 * shop_input_size),\n",
    "                              ReLU(),\n",
    "                              Linear(2 * shop_input_size, shop_output_size))\n",
    "        self.shop_norm3 = LayerNorm(shop_output_size)\n",
    "        \n",
    "        # Food(3x18) -> MultiSelfAttention(20, 4) -> Resid+Norm -> Linear(40) -> ReLU -> Linear(16) -> Norm -> (3x16)\n",
    "        foods_nheads = 4\n",
    "        foods_input_size = n_foods_data + n_foods\n",
    "        foods_npad = foods_nheads - (foods_input_size % foods_nheads)\n",
    "        foods_input_size += foods_npad\n",
    "        foods_output_size = 16\n",
    "        \n",
    "        self.foods_pad = (0, foods_npad)\n",
    "        self.attention3 = MultiheadAttention(foods_input_size, foods_nheads)\n",
    "        self.foods_norm1 = LayerNorm(foods_input_size)\n",
    "        self.ff2 = Sequential(Linear(foods_input_size, 2 * foods_input_size),\n",
    "                              ReLU(),\n",
    "                              Linear(2 * foods_input_size, foods_output_size))\n",
    "        self.foods_norm2 = LayerNorm(foods_output_size)\n",
    "        \n",
    "        # Data(5) -> Norm -> (5)\n",
    "        self.data_norm = LayerNorm(self.n_data)\n",
    "        \n",
    "        # All(144) -> Linear(144) -> ReLU -> Linear(144) -> ReLU -> Linear(132) -> Mask -> SoftMax -> 122\n",
    "        final_input_size = Team.max_size*team_nchannels2 + \\\n",
    "                            Shop.max_size*shop_output_size + \\\n",
    "                            env.max_n_foods*foods_output_size + \\\n",
    "                            self.n_data\n",
    "        final_layer1_size = 400\n",
    "        final_layer2_size = 200\n",
    "        final_output_size = n_actions\n",
    "        \n",
    "        self.final_ff = Sequential(Linear(final_input_size, final_layer1_size),\n",
    "                                   ReLU(),\n",
    "                                   Linear(final_layer1_size, final_layer2_size),\n",
    "                                   ReLU(),\n",
    "                                   Linear(final_layer2_size, final_output_size),\n",
    "                                   # mask?\n",
    "                                   # softmax?\n",
    "                                  )\n",
    "        \n",
    "\n",
    "    def forward(self, team, shop, foods, data):\n",
    "        \"\"\"\n",
    "        param team: np.array with dim (5, x) or (B, 5, x)\n",
    "        param shop: np.array with dim (7, x) or (B, 7, x)\n",
    "        param foods: np.array with dim (3, x) or (B, 3, x)\n",
    "        param shop: np.array with dim (4,) or (B, 4)\n",
    "        \n",
    "        output: tensor(122,) of estimated qvalues for each action\n",
    "        \"\"\"\n",
    "        # convert non-batch input into batch input\n",
    "        if team.ndim == 3 or shop.ndim == 3 or foods.ndim == 3 or data.ndim == 2:\n",
    "            assert team.ndim == shop.ndim == foods.ndim == 3 and data.ndim == 2, \\\n",
    "            f'batched input must have ndim (3, 3, 3, 2), got ({team.ndim}, {shop.ndim}, {foods.ndim}, {data.ndim})'\n",
    "            is_batch = True\n",
    "        else:\n",
    "            assert team.ndim == shop.ndim == foods.ndim == 2 and data.ndim == 1, \\\n",
    "            f'non-batched input must have ndim (2, 2, 2, 1), got ({team.ndim}, {shop.ndim}, {foods.ndim}, {data.ndim})'\n",
    "            is_batch = False\n",
    "            team = np.expand_dims(team, 0)\n",
    "            shop = np.expand_dims(shop, 0)\n",
    "            foods = np.expand_dims(foods, 0)\n",
    "            data = np.expand_dims(data, 0)\n",
    "            \n",
    "        assert team.shape[1] == Team.max_size, f'expected {Team.max_size} but got {team.shape[1]}'\n",
    "        assert shop.shape[1] == Shop.max_size, f'expected {Shop.max_size} but got {shop.shape[1]}'\n",
    "        assert foods.shape[1] == env.max_n_foods, f'expected {env.max_n_foods} but got {foods.shape[1]}'\n",
    "        assert data.shape[1] == self.n_data, f'expected {self.n_data} but got {data.shape[1]}'\n",
    "            \n",
    "        # actual net\n",
    "        team = tensor(np.expand_dims(team, -3))\n",
    "        x1 = self.conv2d(team).squeeze(-1)\n",
    "        x1 = self.relu1(x1)\n",
    "        x1 = self.conv1d(x1)\n",
    "        x1 = self.team_norm(x1)\n",
    "\n",
    "        shop = pad(tensor(shop), self.shop_pad)\n",
    "        x2 = self.shop_norm1(self.attention1(*[shop]*3)[0] + shop)\n",
    "        x2 = self.shop_norm2(self.attention2(*[x2]*3)[0] + x2)\n",
    "        x2 = self.shop_norm3(self.ff1(x2))\n",
    "\n",
    "        foods = pad(tensor(foods), self.foods_pad)\n",
    "        x3 = self.foods_norm1(self.attention3(*[foods]*3)[0] + foods)\n",
    "        x3 = self.foods_norm2(self.ff2(x3))\n",
    "\n",
    "        data = tensor(data)\n",
    "        x4 = self.data_norm(data)\n",
    "\n",
    "        # 250 + 224 + 48 + 6 = 528\n",
    "        full = cat([x.flatten(1) for x in [x1, x2, x3, x4]], 1)\n",
    "        if not is_batch:\n",
    "            full = full.flatten()\n",
    "        \n",
    "        x = self.final_ff(full)\n",
    "        \n",
    "        return x, is_batch\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
